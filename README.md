<!-- # Concrete-Beam-Design
This software is a civil engineering project which designs a rectangular reinforced concrete beam through user specifications and following a set of equations. 
 -->
# Contemporary Issues In Data

## IBM’s AI Facial Recognition — a blatant theft of your photos or an attempt to counter AI prejudice in facial recognition technology?

In this document, I will be analyzing both sides of IBM's controversial facial recognition technology — the use of the user’s photos without consent, and using publicly available photos to reduce bias in facial technology. I highlight two articles which pose opposing arguments in respect to this issue.

## Article 1
The Verge represents the unlawfulness of IBM’s facial recognition technology: [IBM didn’t inform people when it used their Flickr photos for facial recognition training](https://www.theverge.com/2019/3/12/18262646/ibm-didnt-inform-people-when-it-used-their-flickr-photos-for-facial-recognition-training),

Real-time data sets are an essential part of Artificial Intelligence based algorithms in terms of creating accurate conclusions via machine learning. In this case, for IBM’s facial recognition technology, the data set used nearly a million photos taken from individual user’s Flickr accounts without their consent. 
By such photo-scraping activities, the users’ photos would be then stored in the IBM database, which could then be used in ways users are not aware of. The technology employed in this scenario could potentially be used as a surveillance methodology which would directly target individuals such as those whose photos are in IBM’s database. 
It is difficult for IBM to entertain requests of photo removal by each individual user, since the data is exclusively available for academic and corporate research groups, and as users themselves don’t have access to the data set, it would pose a challenge to remove each and every picture associated with the user and their account. 
This scandal was a reminder on how big tech giants have monopolized the industry to an extent that they are able to photo-scrape from public sites for their own personal technologies. This action immediately implies that if one is an active social media user, their photos can be extracted, used and manipulated in any way such companies may deem fit. 

## Article 2
The MIT Technology provides an opposing perspective towards The Verge’s take on IBM’s facial recognition technology:  [IBM’s photo-scraping scandal shows what a weird bubble AI researchers live in]
](https://www.technologyreview.com/2019/03/15/136593/ibms-photo-scraping-scandal-shows-what-a-weird-bubble-ai-researchers-live-in/) 

From an industrial standpoint, IBM followed common procedures in scraping data from the internet and feeding it into their machine learning algorithm. As mentioned by the article, instagram photos have been used as a source for image data as they are categorized by hashtags. In reality, scraping data from public sites is an essential part of Data Science, and is used in abundance in almost all tech industries. 

Furthermore, the goal behind using the Flickr photos as the data set for the facial recognition technology was well suited. Lack of diversity in data is immediately reflected in Artificial Intelligence and the decisions that it makes. By photo-scraping publicly available millions of photos of a vast majority of users on this site, IBM was ensuring that they did not isolate any race or ethnicity while creating the facial recognition technology. 
The prejudice integrated into the technology can be attributed to the lack of diversity in data. The artificial intelligence in this technology has aligned itself with the societal bias associated with race, which has led to dire consequences in regards to acting as an unreliable tool for law enforcement agencies. 
